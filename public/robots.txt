# Medplus Africa - Robots.txt for Search Engine Crawlers
# This file defines crawling rules for search engines

# Default rules for all robots
User-agent: *
Allow: /
Disallow: /app/
Disallow: /admin/
Disallow: /private/
Disallow: /auth-test
Disallow: /manual-setup
Disallow: /database-fix-page
Disallow: /auto-fix
Disallow: /audit
Disallow: /auto-payment-sync
Disallow: /payment-sync

# Specific rules for Googlebot (allow faster crawling)
User-agent: Googlebot
Allow: /
Disallow: /app/
Disallow: /admin/
Disallow: /private/
Crawl-delay: 0
Request-rate: 10/1

# Specific rules for Bingbot
User-agent: Bingbot
Allow: /
Disallow: /app/
Disallow: /admin/
Disallow: /private/
Crawl-delay: 1

# Specific rules for other bots
User-agent: msnbot
Allow: /
Disallow: /app/
Disallow: /admin/
Disallow: /private/

# Sitemap location
Sitemap: https://medplusafrica.com/sitemap.xml
Sitemap: https://medplusafrica.com/sitemap-index.xml
